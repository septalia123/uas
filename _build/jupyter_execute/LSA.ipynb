{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3610daf1",
   "metadata": {},
   "source": [
    "# Crawling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151463f",
   "metadata": {},
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'https://ekbis.sindonews.com/'\n",
    "\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # print(response.url)\n",
    "        for i in range(0, 30):\n",
    "            for data in response.css('body > div:nth-child(5) > section > div.grid_24 > div.homelist-new > ul'):\n",
    "                yield{\n",
    "                    'judul': data.css('li.latest-event.latest-track-' + str(i) + ' > div.homelist-box > div.homelist-title > a::text').extract(),\n",
    "\n",
    "                    'waktu': data.css('li.latest-event.latest-track-' + str(i) + ' > div.homelist-box > div.homelist-top > div.homelist-date::text').extract(),\n",
    "\n",
    "                    'category': data.css('li.latest-event.latest-track-' + str(i) + ' > div.homelist-box > div.homelist-top > div.homelist-channel::text').extract(),\n",
    "\n",
    "                    'isi': data.css('li.latest-event.latest-track-' + str(i) + ' > div.homelist-box > div.homelist-desc::text').extract()\n",
    "                }\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08247996",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04349e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8528/2632210199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# data visualisation and manipulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e5fe",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "790eac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('wrapping-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aebf79b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>waktu</th>\n",
       "      <th>category</th>\n",
       "      <th>isi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wapres Ungkap Data Amerika Soal Ketahanan Pang...</td>\n",
       "      <td>Selasa, 22 Maret 2022 - 17:14 WIB</td>\n",
       "      <td>Sektor Riil</td>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lebih Murah, YLKI Khawatir Konsumen Bakal Migr...</td>\n",
       "      <td>Selasa, 22 Maret 2022 - 16:48 WIB</td>\n",
       "      <td>Sektor Riil</td>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kemenkeu Siapkan 186 Pasal yang Mengatur Penda...</td>\n",
       "      <td>Selasa, 22 Maret 2022 - 16:24 WIB</td>\n",
       "      <td>Makro</td>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan 186 pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menghijau, IHSG Hari Ini Ditutup Tembus Level ...</td>\n",
       "      <td>Selasa, 22 Maret 2022 - 15:37 WIB</td>\n",
       "      <td>Kurs &amp; Saham</td>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tumbuh Berlipat dari PDB, Ekonomi Digital Jadi...</td>\n",
       "      <td>Selasa, 22 Maret 2022 - 15:29 WIB</td>\n",
       "      <td>Makro</td>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Wapres Ungkap Data Amerika Soal Ketahanan Pang...   \n",
       "1  Lebih Murah, YLKI Khawatir Konsumen Bakal Migr...   \n",
       "2  Kemenkeu Siapkan 186 Pasal yang Mengatur Penda...   \n",
       "3  Menghijau, IHSG Hari Ini Ditutup Tembus Level ...   \n",
       "4  Tumbuh Berlipat dari PDB, Ekonomi Digital Jadi...   \n",
       "\n",
       "                               waktu      category  \\\n",
       "0  Selasa, 22 Maret 2022 - 17:14 WIB   Sektor Riil   \n",
       "1  Selasa, 22 Maret 2022 - 16:48 WIB   Sektor Riil   \n",
       "2  Selasa, 22 Maret 2022 - 16:24 WIB         Makro   \n",
       "3  Selasa, 22 Maret 2022 - 15:37 WIB  Kurs & Saham   \n",
       "4  Selasa, 22 Maret 2022 - 15:29 WIB         Makro   \n",
       "\n",
       "                                                 isi  \n",
       "0  Wakil Presiden Maruf Amin mengungkapkan, berda...  \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...  \n",
       "2  Kementerian Keuangan tengah menyiapkan 186 pas...  \n",
       "3  Indeks Harga Saham Gabungan (IHSG) hari ini me...  \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e294d1f",
   "metadata": {},
   "source": [
    "# We will drop the 'publish_date' column as it is useless for our discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "759a23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the publish date.\n",
    "df.drop(['judul'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a7a733a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['waktu'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0cef3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['category'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d77b3e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan 186 pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Menyusul dicabutnya aturan Harga Eceran Tertin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani menyatak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani merespon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harga minyak mentah atau crude oil mengalami k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Menko Airlangga mengakui pelaku UMKM menjadi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asosiasi Pengusaha Ritel Indonesia (Aprindo) m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kementerian Perhubungan menyatakan belum ada k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aturan untuk memulai pembangunan Ibu Kota Nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Otoritas Jasa Keuangan mendorong perusahaan BU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pencabutan Harga Eceran Tertinggi (HET) minyak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Berdasarkan catatan Otoritas Jasa Keuangan (OJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wakil Ketua DPR RI, Rachmat Gobel menyatakan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PT GoTo Gojek Tokopedia Tbk atau GoTo memperpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IHSG hari ini dibuka menguat di 6.974,97 pada ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Harga emas batangan PT Aneka Tambang (Antam) t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>81 perusahaan industri minyak goreng wajib unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fenomena Ghozali Everyday yang sukses menjual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Masyarakat tidak perlu khawatir dan tidak perl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Menteri Koordinator Maritim dan Investasi, Luh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Indeks Harga Saham Gabungan atau IHSG hari ini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Para pemimpin Uni Eropa (UE) menemui jalan bun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Investor asing terpantau melakukan aksi penjua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Selain kenaikan PPN, pemerintah juga akan mene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dow Jones Industrial Average turun 85,08 poin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  isi\n",
       "0   Wakil Presiden Maruf Amin mengungkapkan, berda...\n",
       "1   Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...\n",
       "2   Kementerian Keuangan tengah menyiapkan 186 pas...\n",
       "3   Indeks Harga Saham Gabungan (IHSG) hari ini me...\n",
       "4   Laju pertumbuhan ekonomi digital Indonesia dip...\n",
       "5   Menyusul dicabutnya aturan Harga Eceran Tertin...\n",
       "6   Menteri Keuangan (Menkeu) Sri Mulyani menyatak...\n",
       "7   Menteri Keuangan (Menkeu) Sri Mulyani merespon...\n",
       "8   Harga minyak mentah atau crude oil mengalami k...\n",
       "9   Menko Airlangga mengakui pelaku UMKM menjadi c...\n",
       "10  Asosiasi Pengusaha Ritel Indonesia (Aprindo) m...\n",
       "11  Indeks Harga Saham Gabungan (IHSG) hari ini me...\n",
       "12  Kementerian Perhubungan menyatakan belum ada k...\n",
       "13  Aturan untuk memulai pembangunan Ibu Kota Nega...\n",
       "14  Otoritas Jasa Keuangan mendorong perusahaan BU...\n",
       "15  Pencabutan Harga Eceran Tertinggi (HET) minyak...\n",
       "16  Berdasarkan catatan Otoritas Jasa Keuangan (OJ...\n",
       "17  Wakil Ketua DPR RI, Rachmat Gobel menyatakan, ...\n",
       "18  PT GoTo Gojek Tokopedia Tbk atau GoTo memperpa...\n",
       "19  IHSG hari ini dibuka menguat di 6.974,97 pada ...\n",
       "20  Harga emas batangan PT Aneka Tambang (Antam) t...\n",
       "21  81 perusahaan industri minyak goreng wajib unt...\n",
       "22  Fenomena Ghozali Everyday yang sukses menjual ...\n",
       "23  Masyarakat tidak perlu khawatir dan tidak perl...\n",
       "24  Menteri Koordinator Maritim dan Investasi, Luh...\n",
       "25  Indeks Harga Saham Gabungan atau IHSG hari ini...\n",
       "26  Para pemimpin Uni Eropa (UE) menemui jalan bun...\n",
       "27  Investor asing terpantau melakukan aksi penjua...\n",
       "28  Selain kenaikan PPN, pemerintah juga akan mene...\n",
       "29  Dow Jones Industrial Average turun 85,08 poin ..."
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa1ca2",
   "metadata": {},
   "source": [
    "# Clean Data & Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705173c4",
   "metadata": {},
   "source": [
    "#### Here I have done the data pre-processing. I have used the lemmatizer and can also use the stemmer. Also the stop words have been used along with the words wit lenght shorter than 3 characters to reduce some stray words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "781feb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isi</th>\n",
       "      <th>hapus angka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan 186 pas...</td>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan  pasal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Menyusul dicabutnya aturan Harga Eceran Tertin...</td>\n",
       "      <td>Menyusul dicabutnya aturan Harga Eceran Tertin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani menyatak...</td>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani menyatak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani merespon...</td>\n",
       "      <td>Menteri Keuangan (Menkeu) Sri Mulyani merespon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harga minyak mentah atau crude oil mengalami k...</td>\n",
       "      <td>Harga minyak mentah atau crude oil mengalami k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Menko Airlangga mengakui pelaku UMKM menjadi c...</td>\n",
       "      <td>Menko Airlangga mengakui pelaku UMKM menjadi c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 isi  \\\n",
       "0  Wakil Presiden Maruf Amin mengungkapkan, berda...   \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...   \n",
       "2  Kementerian Keuangan tengah menyiapkan 186 pas...   \n",
       "3  Indeks Harga Saham Gabungan (IHSG) hari ini me...   \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...   \n",
       "5  Menyusul dicabutnya aturan Harga Eceran Tertin...   \n",
       "6  Menteri Keuangan (Menkeu) Sri Mulyani menyatak...   \n",
       "7  Menteri Keuangan (Menkeu) Sri Mulyani merespon...   \n",
       "8  Harga minyak mentah atau crude oil mengalami k...   \n",
       "9  Menko Airlangga mengakui pelaku UMKM menjadi c...   \n",
       "\n",
       "                                         hapus angka  \n",
       "0  Wakil Presiden Maruf Amin mengungkapkan, berda...  \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...  \n",
       "2  Kementerian Keuangan tengah menyiapkan  pasal ...  \n",
       "3  Indeks Harga Saham Gabungan (IHSG) hari ini me...  \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...  \n",
       "5  Menyusul dicabutnya aturan Harga Eceran Tertin...  \n",
       "6  Menteri Keuangan (Menkeu) Sri Mulyani menyatak...  \n",
       "7  Menteri Keuangan (Menkeu) Sri Mulyani merespon...  \n",
       "8  Harga minyak mentah atau crude oil mengalami k...  \n",
       "9  Menko Airlangga mengakui pelaku UMKM menjadi c...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import re #regex library\n",
    "\n",
    "# import word_tokenize & FreqDist from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "df['hapus angka'] = df['isi'].apply(remove_number)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1d1c9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "  le=WordNetLemmatizer()\n",
    "  word_tokens=word_tokenize(headline)\n",
    "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "  cleaned_text=\" \".join(tokens)\n",
    "  return cleaned_text\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a6e23193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taking\n",
    "#nltk.download('wordnet')\n",
    "df['clean_text_isi']=df['hapus angka'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6ab667d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isi</th>\n",
       "      <th>hapus angka</th>\n",
       "      <th>clean_text_isi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "      <td>Wakil Presiden Maruf Amin mengungkapkan, berda...</td>\n",
       "      <td>Wakil Presiden Maruf Amin berdasarkan data Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...</td>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia YLKI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan 186 pas...</td>\n",
       "      <td>Kementerian Keuangan tengah menyiapkan  pasal ...</td>\n",
       "      <td>Kementerian Keuangan pasal aturan turunan Ranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "      <td>Indeks Harga Saham Gabungan (IHSG) hari ini me...</td>\n",
       "      <td>Indeks Harga Saham Gabungan IHSG mendarat zona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 isi  \\\n",
       "0  Wakil Presiden Maruf Amin mengungkapkan, berda...   \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...   \n",
       "2  Kementerian Keuangan tengah menyiapkan 186 pas...   \n",
       "3  Indeks Harga Saham Gabungan (IHSG) hari ini me...   \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...   \n",
       "\n",
       "                                         hapus angka  \\\n",
       "0  Wakil Presiden Maruf Amin mengungkapkan, berda...   \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia (YLKI...   \n",
       "2  Kementerian Keuangan tengah menyiapkan  pasal ...   \n",
       "3  Indeks Harga Saham Gabungan (IHSG) hari ini me...   \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...   \n",
       "\n",
       "                                      clean_text_isi  \n",
       "0  Wakil Presiden Maruf Amin berdasarkan data Ame...  \n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia YLKI ...  \n",
       "2  Kementerian Keuangan pasal aturan turunan Ranc...  \n",
       "3  Indeks Harga Saham Gabungan IHSG mendarat zona...  \n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7d2b5",
   "metadata": {},
   "source": [
    "#### Can see the difference after removal of stopwords and some shorter words. aslo the words have been lemmatized as in 'calls'--->'call'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a73c35",
   "metadata": {},
   "source": [
    "#### Now drop the unpre-processed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ffcc98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['isi'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ac488f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['hapus angka'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "49e93f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_isi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wakil Presiden Maruf Amin berdasarkan data Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ketua Yayasan Lembaga Konsumen Indonesia YLKI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kementerian Keuangan pasal aturan turunan Ranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indeks Harga Saham Gabungan IHSG mendarat zona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laju pertumbuhan ekonomi digital Indonesia dip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clean_text_isi\n",
       "0  Wakil Presiden Maruf Amin berdasarkan data Ame...\n",
       "1  Ketua Yayasan Lembaga Konsumen Indonesia YLKI ...\n",
       "2  Kementerian Keuangan pasal aturan turunan Ranc...\n",
       "3  Indeks Harga Saham Gabungan IHSG mendarat zona...\n",
       "4  Laju pertumbuhan ekonomi digital Indonesia dip..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e867dd6",
   "metadata": {},
   "source": [
    "#### We can also see any particular news headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf416c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wakil Presiden Maruf Amin berdasarkan data Amerika Serikat kemampuan bertahan cadangan pangan Indonesia'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text_isi'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bd696",
   "metadata": {},
   "source": [
    "### EXTRACTING THE FEATURES AND CREATING THE DOCUMENT-TERM-MATRIX ( DTM )\n",
    "In DTM the values are the TFidf values.\n",
    "\n",
    "Also I have specified some parameters of the Tfidf vectorizer.\n",
    "\n",
    "Some important points:-\n",
    "\n",
    "1) LSA is generally implemented with Tfidf values everywhere and not with the Count Vectorizer.\n",
    "\n",
    "2) max_features depends on your computing power and also on eval. metric (coherence score is a metric for topic model). Try the value that gives best eval. metric and doesn't limits processing power.\n",
    "\n",
    "3) Default values for min_df & max_df worked well.\n",
    "\n",
    "4) Can try different values for ngram_range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cf93f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1de158a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect_text=vect.fit_transform(df['clean_text_isi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8072f",
   "metadata": {},
   "source": [
    "#### We can now see the most frequent and rare words in the news headlines based on idf score. The lesser the value; more common is the word in the news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d90b87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 274)\n",
      "  (0, 93)\t0.2165271149567325\n",
      "  (0, 192)\t0.2867690431796365\n",
      "  (0, 39)\t0.2867690431796365\n",
      "  (0, 30)\t0.2867690431796365\n",
      "  (0, 113)\t0.2867690431796365\n",
      "  (0, 241)\t0.2867690431796365\n",
      "  (0, 6)\t0.2867690431796365\n",
      "  (0, 47)\t0.2867690431796365\n",
      "  (0, 25)\t0.25568649478108163\n",
      "  (0, 7)\t0.2867690431796365\n",
      "  (0, 140)\t0.2867690431796365\n",
      "  (0, 226)\t0.2867690431796365\n",
      "  (0, 270)\t0.25568649478108163\n",
      "  (1, 130)\t0.26858557741510825\n",
      "  (1, 115)\t0.21881885803291912\n",
      "  (1, 46)\t0.23947391279261487\n",
      "  (1, 84)\t0.17863945218504915\n",
      "  (1, 176)\t0.15303083349122784\n",
      "  (1, 86)\t0.13994047402823656\n",
      "  (1, 239)\t0.26858557741510825\n",
      "  (1, 59)\t0.26858557741510825\n",
      "  (1, 160)\t0.26858557741510825\n",
      "  (1, 0)\t0.26858557741510825\n",
      "  (1, 260)\t0.26858557741510825\n",
      "  (1, 272)\t0.26858557741510825\n",
      "  :\t:\n",
      "  (27, 235)\t0.2005516098159421\n",
      "  (28, 27)\t0.37180473370818173\n",
      "  (28, 91)\t0.37180473370818173\n",
      "  (28, 109)\t0.37180473370818173\n",
      "  (28, 190)\t0.37180473370818173\n",
      "  (28, 154)\t0.37180473370818173\n",
      "  (28, 202)\t0.37180473370818173\n",
      "  (28, 12)\t0.3029123455706503\n",
      "  (28, 117)\t0.2807339503052941\n",
      "  (29, 2)\t0.2590543725703156\n",
      "  (29, 65)\t0.2590543725703156\n",
      "  (29, 43)\t0.2590543725703156\n",
      "  (29, 223)\t0.2590543725703156\n",
      "  (29, 112)\t0.2590543725703156\n",
      "  (29, 96)\t0.2590543725703156\n",
      "  (29, 33)\t0.2590543725703156\n",
      "  (29, 103)\t0.2590543725703156\n",
      "  (29, 55)\t0.2590543725703156\n",
      "  (29, 261)\t0.2590543725703156\n",
      "  (29, 18)\t0.2590543725703156\n",
      "  (29, 95)\t0.2590543725703156\n",
      "  (29, 105)\t0.2590543725703156\n",
      "  (29, 169)\t0.2309757836682696\n",
      "  (29, 225)\t0.2110537077970523\n",
      "  (29, 235)\t0.17230013483032108\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "print(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "12ddbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9878077",
   "metadata": {},
   "source": [
    "# Topik Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e4ad0",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis (LSA)\n",
    "The first approach that I have used is the LSA. LSA is basically singular value decomposition.\n",
    "\n",
    "SVD decomposes the original DTM into three matrices S=U.(sigma).(V.T). Here the matrix U denotes the document-topic matrix while (V) is the topic-term matrix.\n",
    "\n",
    "Each row of the matrix U(document-term matrix) is the vector representation of the corresponding document. The length of these vectors is the number of desired topics. Vector representation for the terms in our data can be found in the matrix V (term-topic matrix).\n",
    "\n",
    "So, SVD gives us vectors for every document and term in our data. The length of each vector would be k. We can then use these vectors to find similar words and similar documents using the cosine similarity method.\n",
    "\n",
    "We can use the truncatedSVD function to implement LSA. The n_components parameter is the number of topics we wish to extract. The model is then fit and transformed on the result given by vectorizer.\n",
    "\n",
    "Lastly note that LSA and LSI (I for indexing) are the same and the later is just sometimes used in information retrieval contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "836691f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "99ce5d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.83260714e-02 -5.39978479e-02  2.40360697e-02  1.00249014e-01\n",
      "   2.68847273e-02  2.81430783e-01 -2.08211071e-01 -2.65070950e-01\n",
      "  -3.94853124e-01 -2.01902284e-02]\n",
      " [ 3.13807437e-01 -2.88088913e-01 -1.27088864e-01  6.96156174e-02\n",
      "  -5.60164484e-02  1.54771868e-01 -1.23260783e-01 -8.79640144e-03\n",
      "  -1.65713695e-01  2.06284672e-01]\n",
      " [ 4.56680032e-02 -4.83473829e-02  1.64198937e-01 -6.65621485e-02\n",
      "   2.22524491e-01 -2.08648032e-01  4.27046769e-01 -3.02256368e-01\n",
      "  -2.40713789e-01 -3.80016768e-02]\n",
      " [ 4.90902975e-01  5.08784858e-01 -4.41473538e-02  6.63825380e-02\n",
      "   4.77093086e-02 -1.91166002e-01 -1.52399938e-01 -1.82127740e-01\n",
      "   4.88693001e-02  6.36297219e-02]\n",
      " [ 5.11915043e-02 -1.54979353e-02  4.65640229e-02  5.46168223e-02\n",
      "   7.12376162e-02  5.87386608e-01  6.20259322e-02 -3.76490239e-01\n",
      "   1.22688958e-01  1.33280716e-01]\n",
      " [ 5.05662012e-01 -4.12831390e-01 -2.25626775e-01  9.72291718e-03\n",
      "   1.84976939e-01 -1.65559591e-01  1.56010618e-01  2.88293680e-03\n",
      "   1.83474259e-01 -1.19641133e-01]\n",
      " [ 1.67038580e-01 -1.02053592e-01  5.22231187e-01 -5.37979984e-01\n",
      "  -7.42533957e-02  2.69768719e-02 -1.07411393e-01 -7.30418495e-03\n",
      "  -8.26507610e-03 -2.27890654e-01]\n",
      " [ 3.96977970e-01 -2.08414601e-01  3.84278713e-01 -5.04088250e-01\n",
      "  -2.62147486e-01 -2.15972037e-02  9.66365439e-02 -3.00976233e-02\n",
      "   2.67713515e-02  6.84043307e-02]\n",
      " [ 4.37730778e-01  1.20174763e-01  1.21525390e-01 -2.10331871e-01\n",
      "  -2.11370486e-01  1.97712912e-01 -5.37659943e-02 -8.41174436e-02\n",
      "   2.97060545e-03  6.66928500e-02]\n",
      " [ 1.15688654e-02 -1.31890450e-03  6.55375773e-02  3.98234569e-02\n",
      "   2.34829926e-01  3.88564916e-01  1.08098315e-01 -1.50143384e-01\n",
      "   2.59357561e-01  1.97633206e-01]\n",
      " [ 3.32690512e-01 -3.36621902e-01 -2.29795416e-01  9.46883589e-02\n",
      "   1.60250916e-01  3.97243180e-02 -7.31852600e-02 -8.51633388e-02\n",
      "  -4.59132491e-02 -2.91826285e-01]\n",
      " [ 5.80191389e-01  5.89780452e-01 -3.56140234e-02  5.31968097e-02\n",
      "   9.96371426e-03 -9.10054190e-02 -1.01280502e-01 -6.76834576e-02\n",
      "  -5.05032983e-02  6.52996396e-02]\n",
      " [ 4.82202763e-02 -4.39596949e-02  9.20640105e-02 -1.31994521e-01\n",
      "   1.71878751e-01 -2.07163428e-01  4.94483662e-01 -3.45368480e-01\n",
      "  -2.96043330e-01  1.02246527e-01]\n",
      " [ 4.50234389e-02 -4.86341144e-02  2.30219926e-01 -1.41788189e-01\n",
      "   6.79704550e-01 -1.99447063e-02 -1.25170971e-01  1.37662522e-01\n",
      "  -4.69901919e-03  1.65296570e-01]\n",
      " [ 7.81854268e-02 -1.06891866e-01  6.04670109e-01  5.59436886e-01\n",
      "  -9.53516473e-02 -1.30999088e-01  6.40006916e-04  1.85491087e-02\n",
      "  -9.58756113e-03 -8.60683703e-02]\n",
      " [ 5.28308801e-01 -5.14521925e-01 -2.77509488e-01  6.61685036e-02\n",
      "   1.09438717e-01 -6.85834523e-02  1.86099752e-02  3.74444371e-02\n",
      "   6.77168626e-02 -1.76772917e-01]\n",
      " [ 1.07269761e-01 -1.24549933e-01  6.45683784e-01  5.68863211e-01\n",
      "  -5.02490023e-03 -2.78955209e-02 -1.46539260e-02  2.66357431e-03\n",
      "   1.36241545e-02 -3.22979845e-02]\n",
      " [ 2.40623957e-01 -2.84030107e-01 -1.36836580e-01  7.32299006e-02\n",
      "  -1.56622159e-02  1.59914470e-01 -2.12113825e-01 -2.68396314e-02\n",
      "  -2.95830960e-01 -5.72241246e-02]\n",
      " [ 8.46881182e-02  7.71996340e-02  7.16728554e-02  6.72218192e-02\n",
      "  -2.39292906e-02  5.28803917e-02 -4.23724106e-02 -1.63208387e-01\n",
      "   3.80722428e-01 -1.33133849e-01]\n",
      " [ 3.43370430e-01  4.13267694e-01 -1.26068368e-02  3.27007217e-02\n",
      "  -2.61693521e-02  9.18855323e-02  2.67803460e-03  1.59245139e-01\n",
      "  -2.70481250e-01  4.43365606e-02]\n",
      " [ 2.38480888e-01  2.03154811e-01 -8.98157386e-03  2.79591170e-02\n",
      "   1.66538416e-02  2.59458532e-01  3.92414626e-01  4.77783914e-01\n",
      "  -9.49128157e-02 -1.56061393e-01]\n",
      " [ 4.09250499e-01 -3.98962987e-01  3.69358081e-02  2.03357416e-01\n",
      "  -1.59660852e-01 -7.84000866e-03 -4.57546723e-02  1.14270779e-01\n",
      "  -2.57696655e-02  2.55932943e-01]\n",
      " [ 1.79828955e-03 -7.40210592e-04  3.75579637e-03  5.73618077e-03\n",
      "   1.81062164e-02  1.88525830e-01  2.79671973e-02 -2.17118175e-01\n",
      "   9.82375490e-02  1.25121376e-01]\n",
      " [ 2.45172714e-01 -1.70686988e-01  3.19662293e-02 -1.20471283e-01\n",
      "  -2.51502155e-01 -7.23285482e-02  1.69153217e-01  1.64545818e-01\n",
      "   2.52315481e-01  4.89037871e-01]\n",
      " [ 2.96954976e-02 -2.96603243e-02  2.00926746e-01 -1.22255897e-01\n",
      "   5.33780631e-01 -1.67297319e-02 -2.37483258e-01  2.82047516e-01\n",
      "   1.69776863e-02  2.87393751e-01]\n",
      " [ 4.73528620e-01  4.41306780e-01 -6.23720683e-02  7.91215240e-02\n",
      "   7.64997614e-02 -1.11816937e-01 -4.00460207e-02 -3.68252765e-02\n",
      "   1.54144895e-04 -2.61773446e-02]\n",
      " [-9.38525855e-07 -7.62811767e-06  3.40871775e-05 -1.31632733e-04\n",
      "   1.61313389e-03 -3.56152522e-03  3.15233542e-03 -1.15625128e-02\n",
      "  -3.61976579e-02 -2.22562960e-03]\n",
      " [ 1.55098996e-01  1.82743232e-01  4.24615223e-02  9.81649338e-02\n",
      "   9.98968314e-02  3.80016657e-01  3.93536140e-01  2.58398253e-01\n",
      "   1.06305762e-01 -2.62613509e-01]\n",
      " [ 6.14837811e-02 -2.43859768e-02  2.31922578e-01 -3.12243454e-01\n",
      "   5.13576281e-02  1.09102823e-01 -2.52260609e-01  2.01478597e-02\n",
      "   3.79618628e-03 -3.98142095e-01]\n",
      " [ 1.10096408e-01  9.95666288e-02 -3.11041702e-02  4.11207808e-02\n",
      "   1.02661357e-01 -1.57606017e-01 -3.47053637e-02 -2.28000635e-01\n",
      "   4.52072296e-01 -1.69802134e-01]]\n",
      "(30, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "91034092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  3.832607135522223\n",
      "Topic  1  :  -5.399784792009233\n",
      "Topic  2  :  2.4036069728375615\n",
      "Topic  3  :  10.02490137123063\n",
      "Topic  4  :  2.6884727308327987\n",
      "Topic  5  :  28.143078331853577\n",
      "Topic  6  :  -20.821107122012727\n",
      "Topic  7  :  -26.507095037045815\n",
      "Topic  8  :  -39.48531238617555\n",
      "Topic  9  :  -2.0190228364342837\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b5477",
   "metadata": {},
   "source": [
    "#### Similalry for other documents we can do this. However note that values dont add to 1 as in LSA it is not probabiltiy of a topic in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "32375b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 274)\n",
      "[[ 0.03427003  0.00107465  0.0115964  ...  0.03427003  0.03427003\n",
      "   0.05930706]\n",
      " [-0.03738414 -0.00014554  0.01246267 ... -0.03738414 -0.03738414\n",
      "   0.07304079]\n",
      " [-0.02081739  0.0091207  -0.00492329 ... -0.02081739 -0.02081739\n",
      "  -0.00798644]\n",
      " ...\n",
      " [-0.00176988 -0.03145656 -0.05417906 ... -0.00176988 -0.00176988\n",
      "  -0.0499675 ]\n",
      " [-0.04153069  0.05615773  0.1105923  ... -0.04153069 -0.04153069\n",
      "   0.0129145 ]\n",
      " [ 0.05383337  0.04312126 -0.04147381 ...  0.05383337  0.05383337\n",
      "   0.01737356]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d9748",
   "metadata": {},
   "source": [
    "#### Now e can get a list of the important words for each of the 10 topics as shown. For simplicity here I have shown 10 words for each topic.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9917a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "harga minyak goreng perdagangan indeks ihsg selasa gabungan saham sesi \n",
      "\n",
      "Topic 1: \n",
      "perdagangan indeks ihsg gabungan saham menguat selasa sesi poin level \n",
      "\n",
      "Topic 2: \n",
      "perusahaan keuangan bumn kenaikan april menteri dunia menkeu mulyani jasa \n",
      "\n",
      "Topic 3: \n",
      "perusahaan bumn jasa modal otoritas pasar usaha berdasarkan goreng mencapai \n",
      "\n",
      "Topic 4: \n",
      "kota pembangunan aturan negara dimana dikebut dirampungkan ditargetkan nusantara perpres \n",
      "\n",
      "Topic 5: \n",
      "pertumbuhan mencapai ekonomi indonesia laju digital nasional pekan terpantau bruto \n",
      "\n",
      "Topic 6: \n",
      "undang mudik terkait kementerian pekan terpantau aturan pasal pelaksanaan peraturan \n",
      "\n",
      "Topic 7: \n",
      "pekan terpantau menguat batangan emas harganya intip melemah rincian tambang \n",
      "\n",
      "Topic 8: \n",
      "goto saham menyusul nasional airlines average boeing china dipicu eastern \n",
      "\n",
      "Topic 9: \n",
      "masyarakat curah bahan bakar buying diimbau hemat kebutuhan khawatir panic \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7642a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1223b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}